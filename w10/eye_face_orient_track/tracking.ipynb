{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508040c2",
   "metadata": {},
   "source": [
    "https://github.com/serengil/retinaface\n",
    "\n",
    "https://github.com/fkryan/gazelle\n",
    "\n",
    "uv pip install retina-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30c3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from deepface.modules.detection import extract_faces, DetectedFace, FacialAreaRegion, is_valid_landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8994d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Gaze-LLE model\n",
    "model, transform = torch.hub.load('fkryan/gazelle', 'gazelle_dinov2_vitl14_inout')\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d35cfa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['yellow', 'red', 'green', 'blue', 'lime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37048f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinaface import RetinaFace\n",
    "\n",
    "def process_frame(frame):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(frame_rgb)\n",
    "    width, height = img.size\n",
    "    \n",
    "    faces = RetinaFace.detect_faces(frame_rgb)\n",
    "    if not isinstance(faces, dict):\n",
    "        return frame\n",
    "    \n",
    "    bboxes = [faces[key]['facial_area'] for key in faces.keys()]\n",
    "    norm_bboxes = [[np.array(bbox) / np.array([width, height, width, height]) for bbox in bboxes]]\n",
    "    \n",
    "    img_t = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    input_data = {\n",
    "        'images': img_t,\n",
    "        'bboxes': norm_bboxes\n",
    "    }\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_data)\n",
    "        \n",
    "    res_img = viz_all(\n",
    "        img,\n",
    "        output[\"heatmap\"][0],\n",
    "        norm_bboxes[0],\n",
    "        output[\"inout\"][0] if output[\"inout\"] is not None else None,\n",
    "        0.5\n",
    "    )\n",
    "    \n",
    "    res_arr = np.array(res_img)\n",
    "    return cv2.cvtColor(res_arr, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "def process_video(input_path, output_path):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // 2\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) // 2\n",
    "    \n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    try:\n",
    "        with tqdm(total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), desc=\"Processing Video\") as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break                \n",
    "                processed_frame = process_frame(frame)\n",
    "                out.write(processed_frame)                \n",
    "                pbar.update(1)\n",
    "    finally:\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        \n",
    "def viz_all(pil_img, heatmaps, bboxes, inout_scores, inout_threshold):\n",
    "    over_img = pil_img.convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(over_img)\n",
    "    width, height = pil_img.size\n",
    "    \n",
    "    for i in range(len(bboxes)):\n",
    "        bbox = bboxes[i]\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        draw.rectangle([xmin * width, ymin * height, xmax * width, ymax * height], outline=color, width=2)\n",
    "        \n",
    "        if inout_scores is not None:\n",
    "            inout_score = inout_scores[i].item()\n",
    "            text = f\"frame: {inout_score:.2f}\"\n",
    "            text_y = ymax * height + int(height / 100)\n",
    "            draw.text((xmin * width, text_y), text, fill=color)\n",
    "            \n",
    "            if inout_score > inout_threshold:\n",
    "                heatmap = heatmaps[i].cpu().numpy()\n",
    "                max_idx = np.unravel_index(np.argmax(heatmap), heatmap.shape)\n",
    "                gaze_x = max_idx[1] / heatmap.shape[1] * width\n",
    "                gaze_y = max_idx[0] / heatmap.shape[0] * height\n",
    "                bbox_center_x = (xmin + xmax) / 2 * width\n",
    "                bbox_center_y = (ymin + ymax) / 2 * height\n",
    "            \n",
    "                draw.ellipse([(gaze_x - 5, gaze_y - 5), (gaze_x + 5, gaze_y + 5)], fill=color, width=2)\n",
    "                draw.line([(bbox_center_x, bbox_center_y), (gaze_x, gaze_y)], fill=color, width=2)\n",
    "                \n",
    "    return over_img  \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bc49dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_video = 'people_gallery.mp4'\n",
    "# output_video = 'people_gallery_output.mp4'\n",
    "input_video = 'museum2.mp4'\n",
    "output_video = 'museum2_output.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6e5fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Video: 100%|██████████| 603/603 [05:22<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "process_video(input_video, output_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d037f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retina-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
