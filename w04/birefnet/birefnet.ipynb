{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448fc675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d40290073bb4584a20eb0472900bf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5461cb50f34259a32d67a9554049cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/444M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiRefNet is ready to use.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"birefnet/\")\n",
    "from models.birefnet import BiRefNet\n",
    "\n",
    "\n",
    "# Load Model\n",
    "# Option 2 and Option 3 is better for local running -- we can modify codes locally.\n",
    "\n",
    "# # # Option 1: loading BiRefNet with weights:\n",
    "# from transformers import AutoModelForImageSegmentation\n",
    "# birefnet = AutoModelForImageSegmentation.from_pretrained('zhengpeng7/BiRefNet', trust_remote_code=True)\n",
    "\n",
    "# Option-2: loading weights with BiReNet codes:\n",
    "model = [\n",
    "        'zhengpeng7/BiRefNet',\n",
    "        'zhengpeng7/BiRefNet-portrait',\n",
    "        'zhengpeng7/BiRefNet-legacy', 'zhengpeng7/BiRefNet-DIS5K-TR_TEs', 'zhengpeng7/BiRefNet-DIS5K', 'zhengpeng7/BiRefNet-HRSOD', 'zhengpeng7/BiRefNet-COD',\n",
    "        'zhengpeng7/BiRefNet_lite',     # Modify the `bb` in `config.py` to `swin_v1_tiny`.\n",
    "    ][0]\n",
    "birefnet = BiRefNet.from_pretrained(\n",
    "    model\n",
    ")\n",
    "model_name = model.split('/')[-1]\n",
    "\n",
    "# # Option-3: Loading model and weights from local disk:\n",
    "# from utils import check_state_dict\n",
    "\n",
    "# birefnet = BiRefNet(bb_pretrained=False)\n",
    "# state_dict = torch.load('../BiRefNet-general-epoch_244.pth', map_location='cpu', weights_only=True)\n",
    "# state_dict = check_state_dict(state_dict)\n",
    "# birefnet.load_state_dict(state_dict)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.set_float32_matmul_precision(['high', 'highest'][0])\n",
    "\n",
    "birefnet.to(device)\n",
    "birefnet.eval()\n",
    "print('BiRefNet is ready to use.')\n",
    "\n",
    "# Input Data\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((1024, 1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6135dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_src_path = \"well.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9ac35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from image_proc import refine_foreground\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "autocast_ctx = torch.amp.autocast(device_type='cuda', dtype=[torch.float16, torch.bfloat16][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026e2066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "video_src_path: well.mp4\n"
     ]
    }
   ],
   "source": [
    "print('\\nvideo_src_path:', video_src_path)\n",
    "src_dir = os.path.join('frames-{}-video_{}'.format(model_name, os.path.splitext(os.path.basename(video_src_path))[0]))\n",
    "video_ext = os.path.splitext(video_src_path)[-1]\n",
    "video_dst_path_mask = video_src_path.replace(video_ext, '-preds_mask-{}'.format(model_name)+video_ext)\n",
    "video_dst_path_subject = video_src_path.replace(video_ext, '-preds_subject-{}'.format(model_name)+video_ext)\n",
    "vidcap = cv2.VideoCapture(video_src_path)\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "success, image = vidcap.read()\n",
    "\n",
    "video_writer_shape = image.shape[:2][::-1]\n",
    "video_writer_mask = cv2.VideoWriter(video_dst_path_mask, cv2.VideoWriter_fourcc(*'mp4v'), fps, video_writer_shape, isColor=False)\n",
    "video_writer_subject = cv2.VideoWriter(video_dst_path_subject, cv2.VideoWriter_fourcc(*'mp4v'), fps, video_writer_shape, isColor=True)\n",
    "\n",
    "count = 0\n",
    "while success:\n",
    "    os.makedirs(src_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(src_dir, 'frame_{}.png'.format(count)), image)\n",
    "    success, image = vidcap.read()\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8673d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing frames-BiRefNet-video_well/frame_23.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_47.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_71.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_95.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_119.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_143.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_167.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_191.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_215.png / 242 ...\n",
      "Processing frames-BiRefNet-video_well/frame_239.png / 242 ...\n",
      "Mask video has been saved to: well-preds_mask-BiRefNet.mp4\n",
      "Subject video has been saved to: well-preds_subject-BiRefNet.mp4\n",
      "Time cost: 40.42\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from image_proc import refine_foreground\n",
    "from time import time\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "image_paths = sorted(glob(os.path.join(src_dir, '*')), key=lambda x: int(os.path.splitext(os.path.basename(x).split('_')[-1])[0]))   # Sorted by the frame index.\n",
    "# dst_dir = '../predictions'\n",
    "# os.makedirs(dst_dir, exist_ok=True)\n",
    "time_st = time()\n",
    "batch_size = 1\n",
    "for idx in range(0, len(image_paths[:]), batch_size):\n",
    "    image_path = image_paths[idx]\n",
    "    if (idx // batch_size + 1) % int(len(image_paths) // batch_size * 0.1) == 0:\n",
    "        print('Processing {} / {} ...'.format(image_path, len(image_paths)))\n",
    "    input_images_pil = [image.convert(\"RGB\") if image.mode != \"RGB\" else image\n",
    "                        for image in [Image.open(image_path) for image_path in image_paths[idx:idx + batch_size]]]\n",
    "    input_images = [transform_image(input_image).unsqueeze(0).to(device) for input_image in input_images_pil]\n",
    "    input_images = torch.cat(input_images, dim=0)\n",
    "\n",
    "    # Prediction\n",
    "    with autocast_ctx, torch.no_grad():\n",
    "        preds = birefnet(input_images)[-1].sigmoid().to(torch.float32).cpu()\n",
    "\n",
    "    for idx_pred in range(preds.shape[0]):\n",
    "        pred = preds[idx_pred].squeeze()\n",
    "        image = input_images_pil[idx_pred]\n",
    "\n",
    "        # Show Results\n",
    "        pred_pil = transforms.ToPILImage()(pred)\n",
    "        # pred_pil.resize(image.size).save(image_path.replace(src_dir, dst_dir))\n",
    "\n",
    "        image_masked = refine_foreground(image, pred_pil)\n",
    "        image_masked.putalpha(pred_pil.resize(image.size))\n",
    "\n",
    "        video_writer_mask.write(np.array(pred_pil.convert('L').resize(image.size)))\n",
    "        array_foreground = np.array(image_masked)[:, :, :3].astype(np.float32)\n",
    "        array_mask = (np.array(image_masked)[:, :, 3:] / 255).astype(np.float32)\n",
    "        array_background = np.zeros_like(array_foreground)\n",
    "        array_background[:, :, :] = (0, 177, 64)\n",
    "        array_foreground_background = array_foreground * array_mask + array_background * (1 - array_mask)\n",
    "        video_writer_subject.write(cv2.cvtColor(array_foreground_background, cv2.COLOR_RGB2BGR).astype(np.uint8))\n",
    "\n",
    "video_writer_mask.release()\n",
    "video_writer_subject.release()\n",
    "\n",
    "print('Mask video has been saved to:', video_dst_path_mask)\n",
    "print('Subject video has been saved to:', video_dst_path_subject)\n",
    "print('Time cost:', round(time() - time_st, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rebelway ML 3.12",
   "language": "python",
   "name": "rebelway-ml-312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
